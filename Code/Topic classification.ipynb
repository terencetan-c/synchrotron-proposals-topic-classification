{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'GrobidClient' from 'grobid_client' (/Users/fdp54928/Library/CloudStorage/OneDrive-Nexus365/GitHub Repositories/DPhil-Project/Code/venv/lib/python3.11/site-packages/grobid_client/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgrobid_client\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GrobidClient\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'GrobidClient' from 'grobid_client' (/Users/fdp54928/Library/CloudStorage/OneDrive-Nexus365/GitHub Repositories/DPhil-Project/Code/venv/lib/python3.11/site-packages/grobid_client/__init__.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import unicodedata\n",
    "import tensorflow as tf\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialising model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '{insert pathname to model artifacts}/topic_classifier_v1_artifacts/target_vocab.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[96], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m model_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(prefix, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtopic_classifier_v1_artifacts\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Load the needed files\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtarget_vocab.pkl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      7\u001b[0m     target_vocab \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoaded target vocab\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-Nexus365/GitHub Repositories/DPhil-Project/Code/venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py:308\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    303\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    304\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m     )\n\u001b[0;32m--> 308\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '{insert pathname to model artifacts}/topic_classifier_v1_artifacts/target_vocab.pkl'"
     ]
    }
   ],
   "source": [
    "# Define the path\n",
    "prefix = '{insert pathname to model artifacts}'\n",
    "model_path = os.path.join(prefix, 'topic_classifier_v1_artifacts')\n",
    "\n",
    "# Load the needed files\n",
    "with open(os.path.join(model_path, \"target_vocab.pkl\"), \"rb\") as f:\n",
    "    target_vocab = pickle.load(f)\n",
    "\n",
    "print(\"Loaded target vocab\")\n",
    "\n",
    "with open(os.path.join(model_path, \"inv_target_vocab.pkl\"), \"rb\") as f:\n",
    "    inv_target_vocab = pickle.load(f)\n",
    "\n",
    "print(\"Loaded inverse target vocab\")\n",
    "\n",
    "with open(os.path.join(model_path, \"citation_feature_vocab.pkl\"), \"rb\") as f:\n",
    "    citation_feature_vocab = pickle.load(f)\n",
    "    \n",
    "print(\"Loaded citation features vocab.\")\n",
    "\n",
    "with open(os.path.join(model_path, \"gold_to_id_mapping_dict.pkl\"), \"rb\") as f:\n",
    "    gold_to_label_mapping = pickle.load(f)\n",
    "\n",
    "print(\"Loaded gold citation mapping\")\n",
    "\n",
    "with open(os.path.join(model_path, \"gold_citations_dict.pkl\"), \"rb\") as f:\n",
    "    gold_dict = pickle.load(f)\n",
    "    \n",
    "print(\"Loaded gold citation L1\")\n",
    "\n",
    "with open(os.path.join(model_path, \"non_gold_citations_dict.pkl\"), \"rb\") as f:\n",
    "    non_gold_dict = pickle.load(f)\n",
    "\n",
    "print(\"Loaded non-gold citation L1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tokenizer and embedding model\n",
    "emb_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "language_model_name = \\\n",
    "    \"OpenAlex/bert-base-multilingual-cased-finetuned-openalex-topic-classification-title-abstract\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(language_model_name, truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_to_keep_ind(groups):\n",
    "    \"\"\"\n",
    "    Function to determine if a text should be kept or not.\n",
    "\n",
    "    Input:\n",
    "    groups: list of character groups\n",
    "\n",
    "    Output:\n",
    "    0: if text should be not used\n",
    "    1: if text should be used\n",
    "    \"\"\"\n",
    "    # Groups of characters that do not perform well\n",
    "    groups_to_skip = ['HIRAGANA', 'CJK', 'KATAKANA','ARABIC', 'HANGUL', 'THAI','DEVANAGARI','BENGALI',\n",
    "                      'THAANA','GUJARATI','CYRILLIC']\n",
    "    \n",
    "    if any(x in groups_to_skip for x in groups):\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_latin_characters(text):\n",
    "    \"\"\"\n",
    "    Function to remove non-latin characters.\n",
    "\n",
    "    Input:\n",
    "    text: string of characters\n",
    "\n",
    "    Output:\n",
    "    final_char: string of characters with non-latin characters removed\n",
    "    \"\"\"\n",
    "    final_char = []\n",
    "    groups_to_skip = ['HIRAGANA', 'CJK', 'KATAKANA','ARABIC', 'HANGUL', 'THAI','DEVANAGARI','BENGALI',\n",
    "                      'THAANA','GUJARATI','CYRILLIC']\n",
    "    for char in text:\n",
    "        try:\n",
    "            script = unicodedata.name(char).split(\" \")[0]\n",
    "            if script not in groups_to_skip:\n",
    "                final_char.append(char)\n",
    "        except:\n",
    "            pass\n",
    "    return \"\".join(final_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_non_latin_characters(text):\n",
    "    \"\"\"\n",
    "    Function to group non-latin characters and return the number of latin characters.\n",
    "\n",
    "    Input:\n",
    "    text: string of characters\n",
    "\n",
    "    Output:\n",
    "    groups: list of character groups\n",
    "    latin_chars: number of latin characters\n",
    "    \"\"\"\n",
    "    groups = []\n",
    "    latin_chars = []\n",
    "    text = text.replace(\".\", \"\").replace(\" \", \"\")\n",
    "    for char in text:\n",
    "        try:\n",
    "            script = unicodedata.name(char).split(\" \")[0]\n",
    "            if script == 'LATIN':\n",
    "                latin_chars.append(script)\n",
    "            else:\n",
    "                if script not in groups:\n",
    "                    groups.append(script)\n",
    "        except:\n",
    "            if \"UNK\" not in groups:\n",
    "                groups.append(\"UNK\")\n",
    "    return groups, len(latin_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_non_latin_characters(text):\n",
    "    \"\"\"\n",
    "    Function to check if non-latin characters are dominant in a text.\n",
    "\n",
    "    Input:\n",
    "    text: string of characters\n",
    "\n",
    "    Output:\n",
    "    0: if text should be not used\n",
    "    1: if text should be used\n",
    "    \"\"\"\n",
    "    groups, latin_chars = group_non_latin_characters(str(text))\n",
    "    if name_to_keep_ind(groups) == 1:\n",
    "        return 1\n",
    "    elif latin_chars > 20:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_journal_emb(journal_name):\n",
    "    \"\"\"\n",
    "    Function to get journal embedding using SentenceTransformer.\n",
    "\n",
    "    Input:\n",
    "    journal_name: string of journal name\n",
    "\n",
    "    Output:\n",
    "    journal_emb: journal embedding\n",
    "    \"\"\"\n",
    "    # Strip white space\n",
    "    if isinstance(journal_name, str):\n",
    "        journal_name = journal_name.strip()\n",
    "\n",
    "        # Removing all journal names with eBook (most are not descriptive)\n",
    "        if 'eBooks' in journal_name:\n",
    "            return np.zeros(384, dtype=np.float32)\n",
    "\n",
    "        # Check if non-latin characters are dominant (embedding model not good for that)\n",
    "        elif check_for_non_latin_characters(journal_name) == 1:\n",
    "            return emb_model.encode(journal_name)\n",
    "\n",
    "        elif journal_name == '':\n",
    "            return np.zeros(384, dtype=np.float32)\n",
    "\n",
    "        else:\n",
    "            return np.zeros(384, dtype=np.float32)\n",
    "    else:\n",
    "        return np.zeros(384, dtype=np.float32)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(seq, **kwargs):\n",
    "    \"\"\"\n",
    "    Function to tokenize text using model tokenizer.\n",
    "    \n",
    "    Input:\n",
    "    seq: string of text\n",
    "    \n",
    "    Output:\n",
    "    tok_data: dictionary of tokenized text\n",
    "    \"\"\"\n",
    "    tok_data = tokenizer(seq, max_length=512, truncation=True, padding='max_length', **kwargs)\n",
    "    return [tok_data['input_ids'], tok_data['attention_mask']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_level_0_to_1(level_0, level_1):\n",
    "    \"\"\"\n",
    "    Function to move level 0 citations to level 1 citations.\n",
    "    \n",
    "    Input:\n",
    "    level_0: list of level 0 citations\n",
    "    level_1: list of level 1 citations\n",
    "    \n",
    "    Output:\n",
    "    list of final level 1 citations\"\"\"\n",
    "    return list(set(level_0 + level_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_citations_for_model(list_of_links, num_to_take):\n",
    "    \"\"\"\n",
    "    Function to get final citations for model if there are more than num_to_take citations.\n",
    "    \n",
    "    Input:\n",
    "    list_of_links: list of citations\n",
    "    num_to_take: number of citations to take\n",
    "    \n",
    "    Output:\n",
    "    list of final citations\n",
    "    \"\"\"\n",
    "    if len(list_of_links) <= num_to_take:\n",
    "        return list_of_links\n",
    "    else:\n",
    "        return random.sample(list_of_links, num_to_take)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_citations_feature(citations, num_to_keep):\n",
    "    \"\"\"\n",
    "    Function to get final citations for model if there are more than num_to_take citations\n",
    "    and also to map the citations to gold citation ids.\n",
    "\n",
    "    Input:\n",
    "    citations: list of citations\n",
    "    num_to_keep: number of citations to take\n",
    "\n",
    "    Output:\n",
    "    list of final citations\n",
    "    \"\"\"\n",
    "    if citations:\n",
    "        new_citations = get_final_citations_for_model(citations, num_to_keep)\n",
    "        mapped_cites = [gold_to_label_mapping.get(x) for x in new_citations \n",
    "                        if gold_to_label_mapping.get(x)]\n",
    "        temp_feature = [citation_feature_vocab[x] for x in mapped_cites]\n",
    "    \n",
    "        if len(temp_feature) < num_to_keep:\n",
    "            return temp_feature + [0]*(num_to_keep - len(temp_feature))\n",
    "        else:\n",
    "            return temp_feature\n",
    "    else:\n",
    "        return [1] + [0]*(num_to_keep - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_title_and_abstract(title, abstract):\n",
    "    \"\"\"\n",
    "    Function to merge title and abstract together for model input.\n",
    "    \n",
    "    Input:\n",
    "    title: string of title\n",
    "    abstract: string of abstract\n",
    "    \n",
    "    Output:\n",
    "    string of title and abstract merged together\"\"\"\n",
    "    if isinstance(title, str):\n",
    "        if isinstance(abstract, str):\n",
    "            if len(abstract) >=30:\n",
    "                return f\"<TITLE> {title}\\n<ABSTRACT> {abstract[:2500]}\"\n",
    "            else:\n",
    "                return f\"<TITLE> {title}\"\n",
    "        else:\n",
    "            return f\"<TITLE> {title}\"\n",
    "    else:\n",
    "        if isinstance(abstract, str):\n",
    "            if len(abstract) >=30:\n",
    "                return f\"<TITLE> NONE\\n<ABSTRACT> {abstract[:2500]}\"\n",
    "            else:\n",
    "                return \"\"\n",
    "        else:\n",
    "            return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_title(old_title):\n",
    "    \"\"\"\n",
    "    Function to check if title should be kept and then remove non-latin characters. Also\n",
    "    removes some HTML tags from the title.\n",
    "    \n",
    "    Input:\n",
    "    old_title: string of title\n",
    "    \n",
    "    Output:\n",
    "    new_title: string of title with non-latin characters and HTML tags removed\n",
    "    \"\"\"\n",
    "    keep_title = check_for_non_latin_characters(old_title)\n",
    "    if keep_title == 1:\n",
    "        new_title = remove_non_latin_characters(old_title)\n",
    "        if '<' in new_title:\n",
    "            new_title = new_title.replace(\"<i>\", \"\").replace(\"</i>\",\"\")\\\n",
    "                                 .replace(\"<sub>\", \"\").replace(\"</sub>\",\"\") \\\n",
    "                                 .replace(\"<sup>\", \"\").replace(\"</sup>\",\"\") \\\n",
    "                                 .replace(\"<em>\", \"\").replace(\"</em>\",\"\") \\\n",
    "                                 .replace(\"<b>\", \"\").replace(\"</b>\",\"\") \\\n",
    "                                 .replace(\"<I>\", \"\").replace(\"</I>\", \"\") \\\n",
    "                                 .replace(\"<SUB>\", \"\").replace(\"</SUB>\", \"\") \\\n",
    "                                 .replace(\"<scp>\", \"\").replace(\"</scp>\", \"\") \\\n",
    "                                 .replace(\"<font>\", \"\").replace(\"</font>\", \"\") \\\n",
    "                                 .replace(\"<inf>\",\"\").replace(\"</inf>\", \"\") \\\n",
    "                                 .replace(\"<i /> \", \"\") \\\n",
    "                                 .replace(\"<p>\", \"\").replace(\"</p>\",\"\") \\\n",
    "                                 .replace(\"<![CDATA[<B>\", \"\").replace(\"</B>]]>\", \"\") \\\n",
    "                                 .replace(\"<italic>\", \"\").replace(\"</italic>\",\"\")\\\n",
    "                                 .replace(\"<title>\", \"\").replace(\"</title>\", \"\") \\\n",
    "                                 .replace(\"<br>\", \"\").replace(\"</br>\",\"\").replace(\"<br/>\",\"\") \\\n",
    "                                 .replace(\"<B>\", \"\").replace(\"</B>\", \"\") \\\n",
    "                                 .replace(\"<em>\", \"\").replace(\"</em>\", \"\") \\\n",
    "                                 .replace(\"<BR>\", \"\").replace(\"</BR>\", \"\") \\\n",
    "                                 .replace(\"<title>\", \"\").replace(\"</title>\", \"\") \\\n",
    "                                 .replace(\"<strong>\", \"\").replace(\"</strong>\", \"\") \\\n",
    "                                 .replace(\"<formula>\", \"\").replace(\"</formula>\", \"\") \\\n",
    "                                 .replace(\"<roman>\", \"\").replace(\"</roman>\", \"\") \\\n",
    "                                 .replace(\"<SUP>\", \"\").replace(\"</SUP>\", \"\") \\\n",
    "                                 .replace(\"<SSUP>\", \"\").replace(\"</SSUP>\", \"\") \\\n",
    "                                 .replace(\"<sc>\", \"\").replace(\"</sc>\", \"\") \\\n",
    "                                 .replace(\"<subtitle>\", \"\").replace(\"</subtitle>\", \"\") \\\n",
    "                                 .replace(\"<emph/>\", \"\").replace(\"<emph>\", \"\").replace(\"</emph>\", \"\") \\\n",
    "                                 .replace(\"\"\"<p class=\"Body\">\"\"\", \"\") \\\n",
    "                                 .replace(\"<TITLE>\", \"\").replace(\"</TITLE>\", \"\") \\\n",
    "                                 .replace(\"<sub />\", \"\").replace(\"<sub/>\", \"\") \\\n",
    "                                 .replace(\"<mi>\", \"\").replace(\"</mi>\", \"\") \\\n",
    "                                 .replace(\"<bold>\", \"\").replace(\"</bold>\", \"\") \\\n",
    "                                 .replace(\"<mtext>\", \"\").replace(\"</mtext>\", \"\") \\\n",
    "                                 .replace(\"<msub>\", \"\").replace(\"</msub>\", \"\") \\\n",
    "                                 .replace(\"<mrow>\", \"\").replace(\"</mrow>\", \"\") \\\n",
    "                                 .replace(\"</mfenced>\", \"\").replace(\"</math>\", \"\")\n",
    "\n",
    "            if '<mml' in new_title:\n",
    "                all_parts = [x for y in [i.split(\"mml:math>\") for i in new_title.split(\"<mml:math\")] for x in y if x]\n",
    "                final_parts = []\n",
    "                for part in all_parts:\n",
    "                    if re.search(r\"\\>[$%#!^*\\w.,/()+-]*\\<\", part):\n",
    "                        pull_out = re.findall(r\"\\>[$%#!^*\\w.,/()+-]*\\<\", part)\n",
    "                        final_pieces = []\n",
    "                        for piece in pull_out:\n",
    "                            final_pieces.append(piece.replace(\">\", \"\").replace(\"<\", \"\"))\n",
    "                        \n",
    "                        final_parts.append(\" \"+ \"\".join(final_pieces) + \" \")\n",
    "                    else:\n",
    "                        final_parts.append(part)\n",
    "                \n",
    "                new_title = \"\".join(final_parts).strip()\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "            if '<xref' in new_title:\n",
    "                new_title = re.sub(r\"\\<xref[^/]*\\/xref\\>\", \"\", new_title)\n",
    "\n",
    "            if '<inline-formula' in new_title:\n",
    "                new_title = re.sub(r\"\\<inline-formula[^/]*\\/inline-formula\\>\", \"\", new_title)\n",
    "\n",
    "            if '<title' in new_title:\n",
    "                new_title = re.sub(r\"\\<title[^/]*\\/title\\>\", \"\", new_title)\n",
    "\n",
    "            if '<p class=' in new_title:\n",
    "                new_title = re.sub(r\"\\<p class=[^>]*\\>\", \"\", new_title)\n",
    "            \n",
    "            if '<span class=' in new_title:\n",
    "                new_title = re.sub(r\"\\<span class=[^>]*\\>\", \"\", new_title)\n",
    "\n",
    "            if 'mfenced open' in new_title:\n",
    "                new_title = re.sub(r\"\\<mfenced open=[^>]*\\>\", \"\", new_title)\n",
    "            \n",
    "            if 'math xmlns' in new_title:\n",
    "                new_title = re.sub(r\"\\<math xmlns=[^>]*\\>\", \"\", new_title)\n",
    "\n",
    "        if '<' in new_title:\n",
    "            new_title = new_title.replace(\">i<\", \"\").replace(\">/i<\", \"\") \\\n",
    "                                 .replace(\">b<\", \"\").replace(\">/b<\", \"\") \\\n",
    "                                 .replace(\"<inline-formula>\", \"\").replace(\"</inline-formula>\",\"\")\n",
    "\n",
    "        return new_title\n",
    "    else:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_abstract(raw_abstract, inverted=False):\n",
    "    \"\"\"\n",
    "    Function to clean abstract and return it in a format for the model.\n",
    "    \n",
    "    Input:\n",
    "    raw_abstract: string of abstract\n",
    "    inverted: boolean to determine if abstract is inverted index or not\n",
    "    \n",
    "    Output:\n",
    "    final_abstract: string of abstract in format for model\n",
    "    \"\"\"\n",
    "    if inverted:\n",
    "        if isinstance(raw_abstract, dict) | isinstance(raw_abstract, str):\n",
    "            if isinstance(raw_abstract, dict):\n",
    "                invert_abstract = raw_abstract\n",
    "            else:\n",
    "                invert_abstract = json.loads(raw_abstract)\n",
    "            \n",
    "            if invert_abstract.get('IndexLength'):\n",
    "                ab_len = invert_abstract['IndexLength']\n",
    "\n",
    "                if ab_len > 20:\n",
    "                    abstract = [\" \"]*ab_len\n",
    "                    for key, value in invert_abstract['InvertedIndex'].items():\n",
    "                        for i in value:\n",
    "                            abstract[i] = key\n",
    "                    final_abstract = \" \".join(abstract)[:2500]\n",
    "                    keep_abs = check_for_non_latin_characters(final_abstract)\n",
    "                    if keep_abs == 1:\n",
    "                        pass\n",
    "                    else:\n",
    "                        final_abstract = None\n",
    "                else:\n",
    "                    final_abstract = None\n",
    "            else:\n",
    "                if len(invert_abstract) > 20:\n",
    "                    abstract = [\" \"]*1200\n",
    "                    for key, value in invert_abstract.items():\n",
    "                        for i in value:\n",
    "                            try:\n",
    "                                abstract[i] = key\n",
    "                            except:\n",
    "                                pass\n",
    "                    final_abstract = \" \".join(abstract)[:2500].strip()\n",
    "                    keep_abs = check_for_non_latin_characters(final_abstract)\n",
    "                    if keep_abs == 1:\n",
    "                        pass\n",
    "                    else:\n",
    "                        final_abstract = None\n",
    "                else:\n",
    "                    final_abstract = None\n",
    "                \n",
    "        else:\n",
    "            final_abstract = None\n",
    "    else:\n",
    "        ab_len = len(raw_abstract)\n",
    "        if ab_len > 30:\n",
    "            final_abstract = raw_abstract[:2500]\n",
    "            keep_abs = check_for_non_latin_characters(final_abstract)\n",
    "            if keep_abs == 1:\n",
    "                pass\n",
    "            else:\n",
    "                final_abstract = None\n",
    "        else:\n",
    "            final_abstract = None\n",
    "            \n",
    "    return final_abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input_feature(features):\n",
    "    \"\"\"\n",
    "    Function to create input feature for model.\n",
    "    \n",
    "    Input:\n",
    "    features: list of features\n",
    "    \n",
    "    Output:\n",
    "    input_feature: list of features in format for model\"\"\"\n",
    "    # Convert to a tensorflow feature\n",
    "    input_feature = [tf.expand_dims(tf.convert_to_tensor(x), axis=0) for x in [np.array(features[0], dtype=np.int32), \n",
    "                                                                             np.array(features[1], dtype=np.int32), \n",
    "                                                                             features[2]]]\n",
    "\n",
    "    return input_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gold_citations_from_all_citations(all_citations, gold_dict, non_gold_dict):\n",
    "    \"\"\"\n",
    "    Function to get gold citations from all citations.\n",
    "    \n",
    "    Input:\n",
    "    all_citations: list of all citations\n",
    "    gold_dict: dictionary of gold citations\n",
    "    non_gold_dict: dictionary of non-gold citations\n",
    "    \n",
    "    Output:\n",
    "    level_0_gold: list of level 0 gold citations\n",
    "    level_1_gold: list of level 1 gold citations\n",
    "    \"\"\"\n",
    "    if isinstance(all_citations, list):\n",
    "        if len(all_citations) > 200:\n",
    "            all_citations = random.sample(all_citations, 200)\n",
    "        \n",
    "        level_0_gold_temp = [[x, gold_dict.get(x)] for x in all_citations if gold_dict.get(x)]\n",
    "\n",
    "        level_1_gold_temp = [non_gold_dict.get(x) for x in all_citations if non_gold_dict.get(x)]\n",
    "\n",
    "        level_0_gold = [x[0] for x in level_0_gold_temp]\n",
    "        level_1_gold = [y for z in [x[1] for x in level_0_gold_temp] for y in z] + \\\n",
    "                        [x for y in level_1_gold_temp for x in y]\n",
    "\n",
    "        return level_0_gold, level_1_gold\n",
    "    else:\n",
    "        return [], []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(num_classes, emb_table_size, model_chkpt, topk=5):\n",
    "    \"\"\"\n",
    "    Function to create full model.\n",
    "    \n",
    "    Input:\n",
    "    num_classes: number of classes\n",
    "    emb_table_size: size of embedding table\n",
    "    model_chkpt: path to model checkpoint\n",
    "    topk: number of predictions to return\n",
    "    \n",
    "    Output:\n",
    "    model: full model\n",
    "    \"\"\"\n",
    "    # Inputs\n",
    "    citation_0 = tf.keras.layers.Input((16,), dtype=tf.int64, name='citation_0')\n",
    "    citation_1 = tf.keras.layers.Input((128,), dtype=tf.int64, name='citation_1')\n",
    "    journal = tf.keras.layers.Input((384,), dtype=tf.float32, name='journal_emb')\n",
    "    language_model_output = tf.keras.layers.Input((512, 768,), dtype=tf.float32, name='lang_model_output')\n",
    "    \n",
    "    # Create a multi-class classification model using functional API\n",
    "    pooled_language_model_output = tf.keras.layers.GlobalAveragePooling1D()(language_model_output)\n",
    "    citation_emb_layer = tf.keras.layers.Embedding(input_dim=emb_table_size, output_dim=256, mask_zero=True, \n",
    "                                                   trainable=True, name='citation_emb_layer')\n",
    "\n",
    "    citation_0_emb = citation_emb_layer(citation_0)\n",
    "    citation_1_emb = citation_emb_layer(citation_1)\n",
    "\n",
    "    pooled_citation_0 = tf.keras.layers.GlobalAveragePooling1D()(citation_0_emb)\n",
    "    pooled_citation_1 = tf.keras.layers.GlobalAveragePooling1D()(citation_1_emb)\n",
    "\n",
    "    concat_data = tf.keras.layers.Concatenate(name='concat_data', axis=-1)([pooled_language_model_output, pooled_citation_0, \n",
    "                                                                            pooled_citation_1, journal])\n",
    "\n",
    "    # Dense layer 1\n",
    "    dense_output = tf.keras.layers.Dense(2048, activation='relu', kernel_regularizer='L2', name=\"dense_1\")(concat_data)\n",
    "    dense_output = tf.keras.layers.Dropout(0.20, name=\"dropout_1\")(dense_output)\n",
    "    dense_output = tf.keras.layers.LayerNormalization(epsilon=1e-6, name=\"layer_norm_1\")(dense_output)\n",
    "    \n",
    "    # Dense layer 2\n",
    "    dense_output = tf.keras.layers.Dense(1024, activation='relu', kernel_regularizer='L2', name=\"dense_2\")(dense_output)\n",
    "    dense_output = tf.keras.layers.Dropout(0.20, name=\"dropout_2\")(dense_output)\n",
    "    dense_output = tf.keras.layers.LayerNormalization(epsilon=1e-6, name=\"layer_norm_2\")(dense_output)\n",
    "\n",
    "    # Dense layer 3\n",
    "    dense_output_l3 = tf.keras.layers.Dense(512, activation='relu', kernel_regularizer='L2', name=\"dense_3\")(dense_output)\n",
    "    dense_output = tf.keras.layers.Dropout(0.20, name=\"dropout_3\")(dense_output_l3)\n",
    "    dense_output = tf.keras.layers.LayerNormalization(epsilon=1e-6, name=\"layer_norm_3\")(dense_output)\n",
    "    \n",
    "    output_layer = tf.keras.layers.Dense(num_classes, activation='sigmoid', name='output_layer')(dense_output)\n",
    "    topk_outputs = tf.math.top_k(output_layer, k=topk)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=[citation_0, citation_1, journal, language_model_output], \n",
    "                           outputs=topk_outputs)\n",
    "\n",
    "    model.load_weights(model_chkpt)\n",
    "    model.trainable = False\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_ids_and_scores_bad(topic_ids, score, labels, title, abstract, threshold=0.04):\n",
    "    \"\"\"\n",
    "    Function to apply some rules to get the final prediction (some clusters performed worse than others).\n",
    "    \n",
    "    Input:\n",
    "    topic_ids: all ids for raw prediction output\n",
    "    score: all scores for raw prediction output\n",
    "    labels: all labels for raw prediction output\n",
    "    title: title of the work\n",
    "    abstract: abstract of the work\n",
    "    \n",
    "    Output:\n",
    "    final_ids: post-processed final ids\n",
    "    final_scores: post-processed final scores\n",
    "    final_labels: post-processed final labels\n",
    "    \"\"\"\n",
    "    final_ids = [-1]\n",
    "    final_scores = [0.0]\n",
    "    final_labels = [None]\n",
    "    if any(topic_id in topic_ids for topic_id in [13241]):\n",
    "        return final_ids, final_scores, final_labels\n",
    "    elif any(topic_id in topic_ids for topic_id in [12705,13003]):\n",
    "        if title != '':\n",
    "            if check_for_non_latin_characters(title) == 1:\n",
    "                if len(title.split(\" \")) > 9:\n",
    "                    if not isinstance(abstract, str):\n",
    "                        final_ids = [x for x,y in zip(topic_ids, score) if y > threshold]\n",
    "                        final_scores = [y for y in score if y > threshold]\n",
    "                        final_labels = [x for x,y in zip(labels, score) if y > threshold]\n",
    "                        if final_ids:\n",
    "                            return final_ids, final_scores, final_labels\n",
    "                        else:\n",
    "                            return [-1], [0.0], [None]\n",
    "                    elif isinstance(abstract, str):\n",
    "                        if check_for_non_latin_characters(abstract) == 1:\n",
    "                            final_ids = [x for x,y in zip(topic_ids, score) if y > threshold]\n",
    "                            final_scores = [y for y in score if y > 0.05]\n",
    "                            final_labels = [x for x,y in zip(labels, score) if y > threshold]\n",
    "                            if final_ids:\n",
    "                                return final_ids, final_scores, final_labels\n",
    "                            else:\n",
    "                                return [-1], [0.0], [None]\n",
    "                        else:\n",
    "                            return final_ids, final_scores, final_labels\n",
    "                    else:\n",
    "                        return final_ids, final_scores, final_labels\n",
    "                else:\n",
    "                    return final_ids, final_scores, final_labels\n",
    "            else:\n",
    "                return final_ids, final_scores, final_labels\n",
    "        else:\n",
    "            return final_ids, final_scores, final_labels\n",
    "    else:\n",
    "        if any(topic_id in topic_ids for topic_id in [12718,14377,13686,13723]):\n",
    "            final_ids = [x for x,y in zip(topic_ids, score) if (x not in [12718,14377,13686,13723]) & (y > 0.80)]\n",
    "            final_scores = [y for x,y in zip(topic_ids, score) if (x not in [12718,14377,13686,13723]) & (y > 0.80)]\n",
    "            final_labels = [y for x,y,z in zip(topic_ids, labels, score) if (x not in [12718,14377,13686,13723]) & (z > 0.80)]\n",
    "            if final_ids:\n",
    "                return final_ids, final_scores, final_labels\n",
    "            else:\n",
    "                return [-1], [0.0], [None]\n",
    "        elif any(topic_id in topic_ids for topic_id in [13064, 13537]):\n",
    "            if title == 'Frontmatter':\n",
    "                return [-1], [0.0], [None]\n",
    "            else:\n",
    "                final_ids = [x for x,y in zip(topic_ids, score) if (((x in [13064, 13537]) & (y > 0.95)) | \n",
    "                                                                ((x not in [13064, 13537]) & (y > threshold)))]\n",
    "                final_scores = [y for x,y in zip(topic_ids, score) if (((x in [13064, 13537]) & (y > 0.95)) | \n",
    "                                                                    ((x not in [13064, 13537]) & (y > threshold)))]\n",
    "                final_labels = [z for x,y,z in zip(topic_ids, score, labels) if (((x in [13064, 13537]) & (y > 0.95)) | \n",
    "                                                                    ((x not in [13064, 13537]) & (y > threshold)))]\n",
    "                if final_ids:\n",
    "                    return final_ids, final_scores, final_labels\n",
    "                else:\n",
    "                    return [-1], [0.0], [None]\n",
    "        elif any(topic_id in topic_ids for topic_id in [11893, 13459]):\n",
    "            test_scores = [y for x,y in zip(topic_ids, score) if (x in [11893, 13459])]\n",
    "            if topic_ids[0] in [11893, 13459]:\n",
    "                first_pred = 1\n",
    "            else:\n",
    "                first_pred = 0\n",
    "            \n",
    "            if [x for x in test_scores if x > 0.95] & (first_pred == 1):\n",
    "                final_ids = [x for x,y in zip(topic_ids, score) if y > threshold]\n",
    "                final_scores = [y for y in score if y > 0.05]\n",
    "                final_labels = [x for x,y in zip(labels, score) if y > threshold]\n",
    "\n",
    "                if final_ids:\n",
    "                    return final_ids, final_scores, final_labels\n",
    "                else:\n",
    "                    return [-1], [0.0], [None]\n",
    "            elif first_pred == 0:\n",
    "                final_ids = [x for x,y in zip(topic_ids, score) if y > threshold]\n",
    "                final_scores = [y for y in score if y > threshold]\n",
    "                final_labels = [x for x,y in zip(labels, score) if y > threshold]\n",
    "\n",
    "                if final_ids:\n",
    "                    return final_ids, final_scores, final_labels\n",
    "                else:\n",
    "                    return [-1], [0.0], [None]\n",
    "            else:\n",
    "                return [-1], [0.0], [None]\n",
    "        else:\n",
    "            if isinstance(abstract, str) & (title != ''):\n",
    "                if (check_for_non_latin_characters(title) == 1) & (check_for_non_latin_characters(abstract) == 1):\n",
    "                    final_ids = [x for x,y in zip(topic_ids, score) if y > threshold]\n",
    "                    final_scores = [y for y in score if y > threshold]\n",
    "                    final_labels = [x for x,y in zip(labels, score) if y > threshold]\n",
    "    \n",
    "                    if final_ids:\n",
    "                        return final_ids, final_scores, final_labels\n",
    "                    else:\n",
    "                        return [-1], [0.0], [None]\n",
    "                else:\n",
    "                    return [-1], [0.0], [None]\n",
    "            elif title != '':\n",
    "                if (check_for_non_latin_characters(title) == 1):\n",
    "                    final_ids = [x for x,y in zip(topic_ids, score) if y > threshold]\n",
    "                    final_scores = [y for y in score if y > threshold]\n",
    "                    final_labels = [x for x,y in zip(labels, score) if y > threshold]\n",
    "    \n",
    "                    if final_ids:\n",
    "                        return final_ids, final_scores, final_labels\n",
    "                    else:\n",
    "                        return [-1], [0.0], [None]\n",
    "                else:\n",
    "                    return [-1], [0.0], [None]\n",
    "            elif isinstance(abstract, str):\n",
    "                if (check_for_non_latin_characters(abstract) == 1):\n",
    "                    final_ids = [x for x,y in zip(topic_ids, score) if y > threshold]\n",
    "                    final_scores = [y for y in score if y > threshold]\n",
    "                    final_labels = [x for x,y in zip(labels, score) if y > threshold]\n",
    "    \n",
    "                    if final_ids:\n",
    "                        return final_ids, final_scores, final_labels\n",
    "                    else:\n",
    "                        return [-1], [0.0], [None]\n",
    "                else:\n",
    "                    return [-1], [0.0], [None]\n",
    "            else:\n",
    "                return [-1], [0.0], [None]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data_as_df(new_df):\n",
    "    \"\"\"\n",
    "    Function to process data as a dataframe (in batch).\n",
    "    \n",
    "    Input:\n",
    "    new_df: dataframe of data\n",
    "    \n",
    "    Output:\n",
    "    input_df: dataframe of data with predictions\n",
    "    \"\"\"\n",
    "    input_df = new_df.copy()\n",
    "    # Get citations into integer format\n",
    "    input_df['referenced_works'] = input_df['referenced_works'].apply(lambda x: [int(i.split(\"https://openalex.org/W\")[1]) for \n",
    "                                                                             i in x])\n",
    "     # Process title and abstract and tokenize\n",
    "    input_df['title'] = input_df['title'].apply(lambda x: clean_title(x))\n",
    "    input_df['abstract_inverted_index'] = input_df.apply(lambda x: clean_abstract(x.abstract_inverted_index, x.inverted), axis=1)\n",
    "    title_abstract = input_df.apply(lambda x: merge_title_and_abstract(x.title, x.abstract_inverted_index), axis=1).tolist()\n",
    "    tok_inputs_pt = tokenize(title_abstract, return_tensors='pt')       # Tokenise merged title and abstract using tokensier from the OpenAlex BERT model, tokens are returned as a PyTorch tensor\n",
    "    with torch.no_grad():       # Tells PyTorch not to compute gradients (i.e. it is in inference mode) since we are not training the model but just using it to get outputs, saving memory and computation\n",
    "        last_output = pt_model(*tok_inputs_pt).hidden_states[-1]        # Get hidden states from last layer of the OpenAlex BERT model, which often holds the most refined understanding of the input\n",
    "    lang_model_output = last_output.numpy()     # Convert last_output from PyTorch tensor to NumPy array\n",
    "    \n",
    "    # Take citations and return only gold citations (and then convert to label ids)\n",
    "    input_df['referenced_works'] = input_df['referenced_works'].apply(lambda x: get_gold_citations_from_all_citations(x, gold_dict, \n",
    "                                                                                                                      non_gold_dict))\n",
    "    input_df['citation_0'] = input_df['referenced_works'].apply(lambda x: get_final_citations_feature(x[0], 16))\n",
    "    input_df['citation_1'] = input_df['referenced_works'].apply(lambda x: get_final_citations_feature(x[1], 128))    \n",
    "    \n",
    "    # Take in journal name and output journal embedding\n",
    "    input_df['journal_emb'] = input_df['journal_display_name'].apply(get_journal_emb)\n",
    "\n",
    "    # Check completeness of input data\n",
    "    input_df['score_data'] = input_df\\\n",
    "        .apply(lambda x: 0 if ((x.title == \"\") & \n",
    "                               (not x.abstract_inverted_index) & \n",
    "                               (x.citation_0[0]==1) & \n",
    "                               (x.citation_1[0]==1)) else 1, axis=1)\n",
    "\n",
    "    data_to_score = input_df[input_df['score_data']==1].copy()\n",
    "    data_to_not_score = input_df[input_df['score_data']==0][['UID']].copy()\n",
    "\n",
    "    if data_to_score.shape[0] > 0:\n",
    "        # Transform into output for model\n",
    "        data_to_score['input_feature'] = data_to_score.apply(lambda x: create_input_feature([x.citation_0, x.citation_1, \n",
    "                                                                                             x.journal_emb]), axis=1)\n",
    "    \n",
    "        all_rows = [tf.convert_to_tensor([x[0][0] for x in data_to_score['input_feature'].tolist()]), \n",
    "                    tf.convert_to_tensor([x[1][0] for x in data_to_score['input_feature'].tolist()]), \n",
    "                    tf.convert_to_tensor([x[2][0] for x in data_to_score['input_feature'].tolist()]), \n",
    "                    tf.convert_to_tensor(lang_model_output)]\n",
    "        \n",
    "        preds = xla_predict(all_rows)\n",
    "        \n",
    "        data_to_score['preds'] = preds.indices.numpy().tolist()\n",
    "        data_to_score['scores'] = preds.values.numpy().tolist()\n",
    "    else:\n",
    "        data_to_score['preds'] = [[-1]]*data_to_not_score.shape[0]\n",
    "        data_to_score['scores'] = [[0.0000]]*data_to_not_score.shape[0]\n",
    "    \n",
    "    data_to_not_score['preds'] = [[-1]]*data_to_not_score.shape[0]\n",
    "    data_to_not_score['scores'] = [[0.0000]]*data_to_not_score.shape[0]\n",
    "    \n",
    "    return input_df[['UID','title','abstract_inverted_index']].merge(pd.concat([data_to_score[['UID','preds','scores']], \n",
    "                                              data_to_not_score[['UID','preds','scores']]], axis=0), \n",
    "                                   how='left', on='UID')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_pred_check(old_preds, old_scores, old_labels):\n",
    "    \"\"\"\n",
    "    Function to apply some rules to get the final prediction based on scores\n",
    "    \n",
    "    Input:\n",
    "    old_preds: all ids for prediction output\n",
    "    old_scores: all scores for prediction output\n",
    "    old_labels: all labels for prediction output\n",
    "    \n",
    "    Output:\n",
    "    final_ids: post-processed final ids\n",
    "    final_scores: post-processed final scores\n",
    "    final_labels: post-processed final labels\n",
    "    \"\"\"\n",
    "    pred_scores = [[x,y,z] for x,y,z in zip(old_preds, old_scores, old_labels)]\n",
    "\n",
    "    # if any of scores are over 0.9\n",
    "    if [x[1] for x in pred_scores if x[1] > 0.9]:\n",
    "        final_pred_scores = [[x[0], x[1], x[2]] for x in pred_scores if x[1] > 0.9]\n",
    "    elif len(pred_scores) == 1:\n",
    "        final_pred_scores = pred_scores.copy()\n",
    "    elif len(pred_scores) == 2:\n",
    "        scores = [x[1] for x in pred_scores]\n",
    "        if scores[1] < (scores[0]/2):\n",
    "            final_pred_scores = pred_scores[:1].copy()\n",
    "        else:\n",
    "            final_pred_scores = pred_scores.copy()\n",
    "    else:\n",
    "        preds = [x[0] for x in pred_scores]\n",
    "        scores = [x[1] for x in pred_scores]\n",
    "        labels = [x[2] for x in pred_scores]\n",
    "\n",
    "        score_sum = scores[0]\n",
    "        final_pred_scores = pred_scores[:1].copy()\n",
    "        for i, (pred, score, label) in enumerate(zip(preds[1:], scores[1:], labels[1:])):\n",
    "            if score < (score_sum/(i+1)*0.85):\n",
    "                break\n",
    "            else:\n",
    "                final_pred_scores.append([pred, score, label])\n",
    "                score_sum += score\n",
    "\n",
    "    final_preds = [x[0] for x in final_pred_scores]\n",
    "    final_scores = [x[1] for x in final_pred_scores]\n",
    "    final_labels = [x[2] for x in final_pred_scores]\n",
    "    return final_preds, final_scores, final_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized\n"
     ]
    }
   ],
   "source": [
    "# Loading the models\n",
    "pred_model = create_model(len(target_vocab), \n",
    "                          len(citation_feature_vocab)+2,\n",
    "                          os.path.join(model_path, \"model_checkpoint/citation_part_only.keras\"), topk=3)\n",
    "xla_predict = tf.function(pred_model, jit_compile=True)\n",
    "\n",
    "\n",
    "pt_model = AutoModelForSequenceClassification.from_pretrained(language_model_name, output_hidden_states=True)\n",
    "pt_model.eval()\n",
    "\n",
    "print(\"Model initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Return a prediction for the model.\n",
    "\n",
    "Input:\n",
    "JSON of data\n",
    "\n",
    "Output:\n",
    "JSON of predictions\n",
    "\"\"\"\n",
    "# Get input JSON data and convert it to a DF\n",
    "def full_model_prediction(data):\n",
    "    input_json = data\n",
    "    if isinstance(input_json, list):\n",
    "        pass\n",
    "    else:\n",
    "        input_json = json.loads(input_json)\n",
    "\n",
    "    input_df = pd.DataFrame.from_dict(input_json).reset_index().rename(columns={'index': 'UID'})\n",
    "\n",
    "    final_preds = process_data_as_df(input_df)\n",
    "    all_tags = []\n",
    "    threshold = 0.04\n",
    "    for pred,score,title,abstract in zip(final_preds['preds'].tolist(), final_preds['scores'].tolist(), \n",
    "                                final_preds['title'].tolist(), final_preds['abstract_inverted_index'].tolist()):\n",
    "        if pred[0] == -1:\n",
    "            final_ids = [-1]\n",
    "            final_scores = [0.0]\n",
    "            final_labels = [None]\n",
    "        else:\n",
    "            topic_labels = [inv_target_vocab[i] for i in pred]\n",
    "            topic_ids = [int(i.split(': ')[0]) + 10000 for i in topic_labels]\n",
    "            \n",
    "            if any(topic_id in topic_ids for topic_id in [13241,12705,13003,12718,14377,13686,13723,13064, 13537,11893, 13459,13444]):\n",
    "                final_ids, final_scores, final_labels = get_final_ids_and_scores_bad(topic_ids, score, topic_labels, title, abstract)\n",
    "            else:\n",
    "                final_ids = [x for x,y in zip(topic_ids, score) if y > threshold]\n",
    "                final_scores = [y for y in score if y > threshold]\n",
    "                final_labels = [x for x,y in zip(topic_labels, score) if y > threshold]\n",
    "\n",
    "        if final_ids:\n",
    "            if final_ids[0] != -1:\n",
    "                final_ids, final_scores, final_labels = last_pred_check(final_ids, final_scores, final_labels)\n",
    "            else:\n",
    "                pass\n",
    "        else:\n",
    "            final_ids = [-1]\n",
    "            final_scores = [0.0]\n",
    "            final_labels = [None]\n",
    "\n",
    "        single_tags = []\n",
    "        _ = [single_tags.append({'topic_id': i,\n",
    "                                    'topic_label': k, \n",
    "                                    'topic_score': round(float(j), 4)}) if i != -1 else \n",
    "                single_tags.append({'topic_id': -1,\n",
    "                                    'topic_label': None, \n",
    "                                    'topic_score': round(0.0, 4)}) for i,j,k in zip(final_ids, final_scores, final_labels)]\n",
    "        all_tags.append(single_tags)\n",
    "\n",
    "    # Transform predictions to JSON\n",
    "    result = json.dumps(all_tags)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying the proposals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have initialised the model, we import the proposal datafiles we got from the 'Data Processing' Jupyter notebook.\\\n",
    "We have to transform the proposal DataFrames to the specified format for input into the model.\\\n",
    "For proposals with no referenced works, we will set the input features as an empty list.\\\n",
    "Note that we will set the journal name to a blank string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_esrf_non_empty=pd.read_json('/Users/fdp54928/Library/CloudStorage/OneDrive-Nexus365/GitHub Repositories/synchrotron-proposals-topic-classification/Datasets/ESRF/Proposals_ESRF_openalexID')\n",
    "prop_esrf_empty=pd.read_json('/Users/fdp54928/Library/CloudStorage/OneDrive-Nexus365/GitHub Repositories/synchrotron-proposals-topic-classification/Datasets/ESRF/Proposals_ESRF_no_openalexID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Remove some proposals with no publications DOIs (missed them earlier)\n",
    "\n",
    "# prop_esrf_non_empty=prop_esrf_non_empty[prop_esrf_non_empty['openalex_ids'].apply(lambda x: x != [[]])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proposal</th>\n",
       "      <th>summary</th>\n",
       "      <th>title</th>\n",
       "      <th>subject</th>\n",
       "      <th>experiment session doi</th>\n",
       "      <th>publications DOI</th>\n",
       "      <th>openalex_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A01-2-1255</td>\n",
       "      <td>We developed a crystallization strategy that p...</td>\n",
       "      <td>Understanding the structure of two-dimensional...</td>\n",
       "      <td></td>\n",
       "      <td>[10.15151/ESRF-ES-670011338]</td>\n",
       "      <td>[10.1038/s41563-023-01669-z]</td>\n",
       "      <td>[https://openalex.org/W4386923995]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>A01-2-1271</td>\n",
       "      <td>We have synthetized and fully characterized th...</td>\n",
       "      <td>Crystal structure of Pauflerite</td>\n",
       "      <td></td>\n",
       "      <td>[10.15151/ESRF-ES-745262790]</td>\n",
       "      <td>[10.1103/PhysRevMaterials.7.045003]</td>\n",
       "      <td>[https://openalex.org/W4366222734]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>A01-2-1291</td>\n",
       "      <td>Barocaloric (BC) materials are solid state com...</td>\n",
       "      <td>revealing structural mechanisms in high perfor...</td>\n",
       "      <td></td>\n",
       "      <td>[10.15151/ESRF-ES-1106933962]</td>\n",
       "      <td>[10.1002/adma.202310499]</td>\n",
       "      <td>[https://openalex.org/W4389817329]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>A01-2-1313</td>\n",
       "      <td>Conversion/alloying materials (CAMs) as anodes...</td>\n",
       "      <td>High-rate operando XRD studies on conversion/a...</td>\n",
       "      <td></td>\n",
       "      <td>[10.15151/ESRF-ES-1361431177, 10.15151/ESRF-ES...</td>\n",
       "      <td>[10.1021/acs.chemmater.4c01104]</td>\n",
       "      <td>[https://openalex.org/W4399629050]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>A01-2-1324</td>\n",
       "      <td>In this experiment, we aim to study mechanism ...</td>\n",
       "      <td>In-situ graphene formation in a nanoporous syn...</td>\n",
       "      <td></td>\n",
       "      <td>[10.15151/ESRF-ES-1578692758]</td>\n",
       "      <td>[10.1002/adem.202301415]</td>\n",
       "      <td>[https://openalex.org/W4388771859]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4362</th>\n",
       "      <td>SC-5324</td>\n",
       "      <td>Chocolate is a popular confectionary and its d...</td>\n",
       "      <td>Understanding of the crystallization behaviour...</td>\n",
       "      <td>Soft Condensed Matter Science</td>\n",
       "      <td>[10.15151/ESRF-ES-886331097]</td>\n",
       "      <td>[10.1016/j.foodres.2023.113864]</td>\n",
       "      <td>[https://openalex.org/W4390047110]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4363</th>\n",
       "      <td>SC-5327</td>\n",
       "      <td>The interaction kinetics of lipid nanoparticle...</td>\n",
       "      <td>Millisecond Rapid Mixing Stopped-Flow BioSAXS ...</td>\n",
       "      <td>Soft Condensed Matter Science</td>\n",
       "      <td>[10.15151/ESRF-ES-896696151]</td>\n",
       "      <td>[10.1002/anie.202304977, 10.1021/acs.jpcb.4c03...</td>\n",
       "      <td>[https://openalex.org/W4382777310, https://ope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4391</th>\n",
       "      <td>SC-5396</td>\n",
       "      <td>In this proposal we aim to understand how the ...</td>\n",
       "      <td>Microstructural response of graphite nanoplate...</td>\n",
       "      <td>Soft Condensed Matter Science</td>\n",
       "      <td>[10.15151/ESRF-ES-1210181200]</td>\n",
       "      <td>[10.1016/j.colsurfa.2024.134997]</td>\n",
       "      <td>[https://openalex.org/W4401502799]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4414</th>\n",
       "      <td>SC-5455</td>\n",
       "      <td>Carrageenan and gelatin are biopolymers that m...</td>\n",
       "      <td>Bio-polymers thermos-reversible gelation, a co...</td>\n",
       "      <td>Soft Condensed Matter Science</td>\n",
       "      <td>[10.15151/ESRF-ES-1347514467]</td>\n",
       "      <td>[10.1103/PhysRevMaterials.8.L072601]</td>\n",
       "      <td>[https://openalex.org/W4400448992]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4466</th>\n",
       "      <td>SC-5576</td>\n",
       "      <td>Hybrid perovskite structures are promising mat...</td>\n",
       "      <td>Lead halide perovskite crystallization in-situ...</td>\n",
       "      <td>Soft Condensed Matter Science</td>\n",
       "      <td>[10.15151/ESRF-ES-1469695094]</td>\n",
       "      <td>[10.1002/advs.202405622]</td>\n",
       "      <td>[https://openalex.org/W4400334870]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>534 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        proposal                                            summary  \\\n",
       "4     A01-2-1255  We developed a crystallization strategy that p...   \n",
       "13    A01-2-1271  We have synthetized and fully characterized th...   \n",
       "26    A01-2-1291  Barocaloric (BC) materials are solid state com...   \n",
       "38    A01-2-1313  Conversion/alloying materials (CAMs) as anodes...   \n",
       "41    A01-2-1324  In this experiment, we aim to study mechanism ...   \n",
       "...          ...                                                ...   \n",
       "4362     SC-5324  Chocolate is a popular confectionary and its d...   \n",
       "4363     SC-5327  The interaction kinetics of lipid nanoparticle...   \n",
       "4391     SC-5396  In this proposal we aim to understand how the ...   \n",
       "4414     SC-5455  Carrageenan and gelatin are biopolymers that m...   \n",
       "4466     SC-5576  Hybrid perovskite structures are promising mat...   \n",
       "\n",
       "                                                  title  \\\n",
       "4     Understanding the structure of two-dimensional...   \n",
       "13                      Crystal structure of Pauflerite   \n",
       "26    revealing structural mechanisms in high perfor...   \n",
       "38    High-rate operando XRD studies on conversion/a...   \n",
       "41    In-situ graphene formation in a nanoporous syn...   \n",
       "...                                                 ...   \n",
       "4362  Understanding of the crystallization behaviour...   \n",
       "4363  Millisecond Rapid Mixing Stopped-Flow BioSAXS ...   \n",
       "4391  Microstructural response of graphite nanoplate...   \n",
       "4414  Bio-polymers thermos-reversible gelation, a co...   \n",
       "4466  Lead halide perovskite crystallization in-situ...   \n",
       "\n",
       "                            subject  \\\n",
       "4                                     \n",
       "13                                    \n",
       "26                                    \n",
       "38                                    \n",
       "41                                    \n",
       "...                             ...   \n",
       "4362  Soft Condensed Matter Science   \n",
       "4363  Soft Condensed Matter Science   \n",
       "4391  Soft Condensed Matter Science   \n",
       "4414  Soft Condensed Matter Science   \n",
       "4466  Soft Condensed Matter Science   \n",
       "\n",
       "                                 experiment session doi  \\\n",
       "4                          [10.15151/ESRF-ES-670011338]   \n",
       "13                         [10.15151/ESRF-ES-745262790]   \n",
       "26                        [10.15151/ESRF-ES-1106933962]   \n",
       "38    [10.15151/ESRF-ES-1361431177, 10.15151/ESRF-ES...   \n",
       "41                        [10.15151/ESRF-ES-1578692758]   \n",
       "...                                                 ...   \n",
       "4362                       [10.15151/ESRF-ES-886331097]   \n",
       "4363                       [10.15151/ESRF-ES-896696151]   \n",
       "4391                      [10.15151/ESRF-ES-1210181200]   \n",
       "4414                      [10.15151/ESRF-ES-1347514467]   \n",
       "4466                      [10.15151/ESRF-ES-1469695094]   \n",
       "\n",
       "                                       publications DOI  \\\n",
       "4                          [10.1038/s41563-023-01669-z]   \n",
       "13                  [10.1103/PhysRevMaterials.7.045003]   \n",
       "26                             [10.1002/adma.202310499]   \n",
       "38                      [10.1021/acs.chemmater.4c01104]   \n",
       "41                             [10.1002/adem.202301415]   \n",
       "...                                                 ...   \n",
       "4362                    [10.1016/j.foodres.2023.113864]   \n",
       "4363  [10.1002/anie.202304977, 10.1021/acs.jpcb.4c03...   \n",
       "4391                   [10.1016/j.colsurfa.2024.134997]   \n",
       "4414               [10.1103/PhysRevMaterials.8.L072601]   \n",
       "4466                           [10.1002/advs.202405622]   \n",
       "\n",
       "                                           openalex_ids  \n",
       "4                    [https://openalex.org/W4386923995]  \n",
       "13                   [https://openalex.org/W4366222734]  \n",
       "26                   [https://openalex.org/W4389817329]  \n",
       "38                   [https://openalex.org/W4399629050]  \n",
       "41                   [https://openalex.org/W4388771859]  \n",
       "...                                                 ...  \n",
       "4362                 [https://openalex.org/W4390047110]  \n",
       "4363  [https://openalex.org/W4382777310, https://ope...  \n",
       "4391                 [https://openalex.org/W4401502799]  \n",
       "4414                 [https://openalex.org/W4400448992]  \n",
       "4466                 [https://openalex.org/W4400334870]  \n",
       "\n",
       "[534 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prop_esrf_non_empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the column names\n",
    "\n",
    "prop_esrf_non_empty=prop_esrf_non_empty.rename(columns={'summary':'abstract_inverted_index','openalex_ids':'referenced_works','subject':'journal_display_name'})\n",
    "prop_esrf_empty=prop_esrf_empty.rename(columns={'summary':'abstract_inverted_index','openalex_ids':'referenced_works','subject':'journal_display_name'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all null values in the title and abstract columns with blank string\n",
    "\n",
    "prop_esrf_non_empty['abstract_inverted_index'].fillna('',inplace=True)\n",
    "prop_esrf_non_empty['title'].fillna('',inplace=True)\n",
    "\n",
    "prop_esrf_empty['abstract_inverted_index'].fillna('',inplace=True)\n",
    "prop_esrf_empty['title'].fillna('',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training batch\n",
    "\n",
    "batch_non_empty=prop_esrf_non_empty[['title','abstract_inverted_index','referenced_works','journal_display_name']].to_dict(orient='records')\n",
    "batch_empty=prop_esrf_empty[['title','abstract_inverted_index','referenced_works','journal_display_name']].to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the input features\n",
    "\n",
    "for dict in batch_non_empty:\n",
    "    dict['inverted']=False\n",
    "\n",
    "for dict in batch_empty:\n",
    "    dict['inverted']=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_non_empty[687]['referenced_works']=['https://openalex.org/W3115800845',\n",
    "#   'https://openalex.org/W3120781410']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have formatted the input data correctly, we can proceed with topic classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proposals with referenced works\n",
    "results_non_empty=[]\n",
    "for single in batch_non_empty:\n",
    "    result=full_model_prediction([single])\n",
    "    results_non_empty.append(json.loads(result)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proposals with no referenced works\n",
    "results_empty=[]\n",
    "for single in batch_empty:\n",
    "    result=full_model_prediction([single])\n",
    "    results_empty.append(json.loads(result)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the list of topic predictions as a dict value to the batch lists\n",
    "\n",
    "n = len(batch_non_empty)\n",
    "for i in range(n):\n",
    "    batch_non_empty[i]['topic predictions']=results_non_empty[i]\n",
    "    batch_non_empty[i]['has referenced works']=1\n",
    "    batch_non_empty[i]['Proposal number']=prop_esrf_non_empty['proposal'].to_list()[i]\n",
    "    batch_non_empty[i]['Experiment session DOI']=prop_esrf_non_empty['experiment session doi'].to_list()[i]\n",
    "    batch_non_empty[i]['referenced_works DOI']=prop_esrf_non_empty['publications DOI'].to_list()[i]\n",
    "\n",
    "\n",
    "\n",
    "n = len(batch_empty)\n",
    "for i in range(n):\n",
    "    batch_empty[i]['topic predictions']=results_empty[i]\n",
    "    batch_empty[i]['has referenced works']=0\n",
    "    batch_empty[i]['Proposal number']=prop_esrf_empty['proposal'].to_list()[i]\n",
    "    batch_empty[i]['Experiment session DOI']=prop_esrf_empty['experiment session doi'].to_list()[i]\n",
    "    batch_empty[i]['referenced_works DOI']=prop_esrf_empty['publications DOI'].to_list()[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate both non_empty and empty batches\n",
    "prop_esrf_pred=batch_non_empty + batch_empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to json string\n",
    "json_string=json.dumps(prop_esrf_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the JSON string to a file\n",
    "with open('{insert pathname here}/Datasets/ESRF/Proposals_ESRF_Predictions', 'w') as file:\n",
    "    file.write(json_string)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
